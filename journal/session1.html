<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>Session 1 — Ray Casting</title>
  <link rel="stylesheet" href="style.css"/>
</head>
<body>
  <header class="subpage-header">
    <h1>Session 1 — Ray Casting</h1>
    <p>This session introduces the core ideas behind a simple ray tracer. We learn how to send rays from the camera, detect the first object they touch, and shade the result with a basic light model.</p>
  </header>

  <main class="session-content">

    <!-- Exercise 1 -->
    <section class="exercise" id="ex1">
      <h2>Exercise 1 — Ray generation (pinhole camera)</h2>

      <p>
        I first created a 512×512 canvas and initialized WebGPU to render into it.
        Then I built a minimal pipeline that draws a rectangle (triangle strip) using a WGSL shader.
      </p>

      <p>
        Compared to just clearing the screen, I switched to a full-screen quad and passed the image-plane
        coordinates from the vertex shader to the fragment shader.
        In the fragment shader, I implemented a simple <b>Ray</b> struct and generated rays using a
        <b>pinhole camera model</b>.
      </p>

      <p>
        As a debug test, I output the ray direction as RGB (scaled to [0,1]), which produces the expected gradient.
      </p>

      <img src="images/w1_ex1.png" alt="Exercise 1 result"/>

      <p>
        Source code:
        <a href="https://github.com/Rach0o0/Rendering-class/tree/main/Session1/1" target="_blank">
          GitHub – Worksheet 1 / Exercise 1
        </a>
      </p>
    </section>


    <!-- Exercise 2 -->
    <section class="exercise" id="ex2">
      <h2>Exercise 2 — Uniforms and correct aspect ratio</h2>

      <p>
        Compared to Exercise 1, I introduced a <b>Uniforms</b> struct to send camera parameters from JavaScript to WGSL.
        It contains the <b>aspect ratio</b> and the <b>camera constant (zoom)</b>.
      </p>

      <p>
        I also changed the canvas resolution to a non-square size to verify that the aspect ratio is handled correctly.
        Using <b>MV.js</b>, I precomputed the camera basis vectors (eye position + image plane basis) in JavaScript
        and uploaded them as uniforms.
      </p>

      <p>
        This makes ray generation consistent even when the canvas size changes.
      </p>

      <img src="images/w1_ex2.png" alt="Exercise 2 result"/>

      <p>
        Source code:
        <a href="https://github.com/Rach0o0/Rendering-class/tree/main/Session1/2" target="_blank">
          GitHub – Worksheet 1 / Exercise 2
        </a>
      </p>
    </section>



    <!-- Exercise 3 -->
    <section class="exercise" id="ex3">
      <h2>Exercise 3 — Ray intersections (plane, sphere, triangle)</h2>

      <p>
        Compared to Exercise 2, I added a <b>HitInfo</b> struct to store intersection results (hit flag, distance, normal, etc.).
        I then implemented intersection tests for a <b>plane</b>, a <b>sphere</b>, and a <b>triangle</b>.
      </p>

      <p>
        In the fragment shader, I call these intersection functions to render the default scene.
        If a ray hits an object, I output its assigned color; otherwise I keep the previous background color.
      </p>

      <p>
        To ensure correct visibility, I update <b>tmax</b> after a hit so that the renderer keeps only the <b>closest intersection</b>.
      </p>

      <img src="images/w1_ex3.png" alt="Exercise 3 result"/>

      <p>
        Source code:
        <a href="https://github.com/Rach0o0/Rendering-class/tree/main/Session1/3" target="_blank">
          GitHub – Worksheet 1 / Exercise 3
        </a>
      </p>
    </section>



    <!-- Exercise 4 -->
    <section class="exercise" id="ex4">
      <h2>Exercise 4 — Direct lighting (point light + diffuse shading)</h2>

      <p>
        Compared to Exercise 3, I implemented actual shading instead of flat object colors.
        I added a <b>Light</b> struct that returns the incident radiance <b>Li</b>, the light direction, and the distance.
      </p>

      <p>
        I implemented a <b>point light sampling</b> function using Kepler’s inverse-square law,
        and a diffuse shading function using <b>Lambert’s cosine law</b>.
        The final pixel color stores the observed radiance <b>Lo</b>.
      </p>

      <img src="images/w1_ex4.png" alt="Exercise 4 result"/>

      <p>
        Source code:
        <a href="https://github.com/Rach0o0/Rendering-class/tree/main/Session1/4" target="_blank">
          GitHub – Worksheet 1 / Exercise 4
        </a>
      </p>
    </section>


    <!-- Exercise 5 -->
    <section class="exercise" id="ex5">
      <h2>Exercise 5 — Zoom interface</h2>

      <p>
        Finally, I added a simple HTML/JavaScript interface (slider / mouse wheel) to control the <b>camera constant</b>.
        When the zoom value changes, the uniforms are updated and the scene is re-rendered.
      </p>

      <p>
        Optionally, gamma correction can also be controlled through the UI to adjust the final display.
      </p>

      <img src="images/w1_ex5.png" alt="Exercise 5 result"/>

      <p>
        Source code:
        <a href="https://github.com/Rach0o0/Rendering-class/tree/main/Session1/5" target="_blank">
          GitHub – Worksheet 1 / Exercise 5
        </a>
      </p>
    </section>


  </main>

  <footer>
    <a class="back" href="index.html">← Back to Home</a>
  </footer>
</body>
</html>
